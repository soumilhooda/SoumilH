---
layout: default
title: Rashomon Effect, Rubicon Boundaries and Video Understanding Models.
---
<h1>Rashomon Effect, Rubicon Boundaries and Video Understanding Models.</h1>
<p>
    <br>This piece is losely based on Dima Damen's talk that I recently had the pleasure to attend. She talked about the egocentric approach to video understanding models. She mentioned the inconsistencies in temporal labelling that are present in video understanding datasets. Something hard labelled as 'sprinkle salt' can also be classified as 'season dish'.

    <br>This reminded me of the Rashomon Effect. As Wikipedia defines it, 'The Rashomon effect is the situation in which an event is given contradictory interpretations or descriptions by the individuals involved, and is a storytelling and writing method in cinema meant to provide different perspectives and points of view of the same incident. The term, derived from the 1950 Japanese film Rashomon, is used to describe the phenomenon of the unreliability of eyewitnesses.' I had come to know of the effect when I once happened to go over the Principles of Machine Learning, where it was reflecting the non-existence of a best model for a finite dataset. 

    <br>This got me gripped on to how she happened to attempt to solve the problem. Rubicon Boundaries. 
</p>
<p>
    <br><h3>Action Phases modeled by Rubicons [1]</h3>
   
    <br>Beyond the helpful conceptual distinction between goal-setting and goal-striving, the Rubicon Model of Action Phases goes further. Although the model keeps these two issues with goal-oriented behaviour apart, it incorporates them both into a single theoretical model, allowing for an analysis of how they relate to one another. The model proposes four distinct phases: first, the predecisional phase; second, the postdecisional but still preactional phase; third, the actional phase; and fourth, the postactional phase. These phases divide the sequence of events taking place within this extensive time frame into discrete phenomena. Three distinct transition points or boundaries separate these phases: the decision-making process, the start of the appropriate actions, and the completion of those actions.

    <br>Using this knowledge David Moltisanti et al. worked on Labeling Temporal Bounds for Object Interactions in Egocentric Video [2].
</p>
<p>
    <br><h3>Trespassing the Boundaries</h3>
    
    <br>The paper focuses on identifying temporal bound inconsistencies and evaluating how they affect object interaction recognition, but they go a step further by proposing a method for consistently labelling temporal bounds drawn from research on human mindset.
    
    <br> Egocentric datasets at the time were annotated for a number of action classes, described by a noun-verb pair and a temporal bound (start time and end time). But there is very little information provided on how these manual labels are acquired.
    
    <br> They then involve Rubicon Boundaries, a model that is named after the historical fact of Caesar crossing the Rubicon river, which became a metaphor for deliberately proceeding past a point of no return, which in our case is the transition point that signals the beginning of an action. 
   
    <br> THey obtained good results this way, but proposed a further question. <bold>Which temporal granularity?</bold> The Rubicon Boundaries deal with consistent temporal boundary labelling, but they do not deal with the issue of action granularity. Is cutting a whole tomato one long action, or does it involve several short cuts? The Rubicon Boundaries model talks about actions in relation to the objective a person wants to reach. Annotating the level of granularity consistently for an object interaction is a different issue, and they pose the need for its addressal.
</p>
<p>
    <br><h3>References</h3>
    <br>[1] <bold></bold>Action Phases and Mind-Sets</bold>, <emph>Peter M. Gollwitzer</emph> in <bold>Handbok of Motivation and Cognition</bold>.
    <br>[2] <bold>Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video</bold>, <emph>Davide Moltisanti, Michael Wray, Walterio Mayol-Cuevas and Dima Damen</emph> at <bold>ICCV 2017</bold>.
</p>
